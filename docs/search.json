[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sai Ram Kuchana",
    "section": "",
    "text": "Linkedin\n  \n  \n    \n     Email\n  \n\n  \n  \nHi, I’m Ram!\nHere, I post my projects whenever i have done something new and got time."
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Sai Ram Kuchana",
    "section": "Projects",
    "text": "Projects\n\n\n\n\n\n\n\n\n\n\nUsing a pre-trained BERT model for text prediction and analysing its self-attention scores\n\n\n\nPyTorch\n\n\nPIL\n\n\nTransformers\n\n\nPython\n\n\nAll\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeveloping neural network models for classification problems using PyTorch\n\n\n\nPyTorch\n\n\nNumPy\n\n\nMatplotlib\n\n\nscikit-learn\n\n\nPython\n\n\nAll\n\n\n\n\n\n\n\n\n\n\n\nBuilding a model to identify the type of clothing in the image\n\n\n\nPyTorch\n\n\nMatplotlib\n\n\nscikit-learn\n\n\nPython\n\n\nAll\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNearest neighbor for handwritten digit recognition\n\n\n\nNumPy\n\n\nMatplotlib\n\n\nscikit-learn\n\n\nPython\n\n\nAll\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraining an AI to play a game using reinforcement learning\n\n\n\nPython\n\n\nAll\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating parse trees and extracting noun phrases\n\n\n\nNLTK\n\n\nPython\n\n\nAll\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing SQL to find the missing packages in the mail delivery service’s database\n\n\n\nSQL\n\n\nAll\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoft deletions, views, and triggers in the context of a museum’s database\n\n\n\nSQL\n\n\nAll\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding a dashboard for the sales using Tableau\n\n\n\nTableau\n\n\nAll\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/SQLPackages/packages.html",
    "href": "projects/SQLPackages/packages.html",
    "title": "Using SQL to find the missing packages in the mail delivery service’s database",
    "section": "",
    "text": "Imagine you are a mail clerk for the city of Boston who oversees the delivery of mail across the city. For the most part, all packages sent are eventually delivered. However, every once in while, a mystery lands on your desk: a missing package! For each customer that comes to you with a report of a missing package, your task is to help each customer find their missing package and answer their relevant questions using just the information in the mail delivery service’s database, packages.db, which contains data on the transit of packages around the city.\nThe specific problems to solve and the schema of the database are described below.\n\n\nThe first report of a missing package comes from Anneke. Anneke walks up to your counter and tells you the following:\n\n\n\n\n\n\nClerk, my name’s Anneke. I live over at 900 Somerville Avenue. Not long ago, I sent out a special letter. It’s meant for my friend Varsha. She’s starting a new chapter of her life at 2 Finnegan Street, uptown. (That address, let me tell you: it was a bit tricky to get right the first time.) The letter is a congratulatory note—a cheery little paper hug from me to her, to celebrate this big move of hers. Can you check if it’s made its way to her yet?\n\n\n\nYour job is to find out:\n\nAt what type of address did the Lost Letter end up?\nAt what address did the Lost Letter end up?\n\n\n\n\nThe second report of a missing package comes from a mysterious fellow from out of town. They walk up to your counter and tell you the following:\n\n\n\n\n\n\nGood day to you, deliverer of the mail. You might remember that not too long ago I made my way over from the town of Fiftyville. I gave a certain box into your reliable hands and asked you to keep things low. My associate has been expecting the package for a while now. And yet, it appears to have grown wings and flown away. Ha! Any chance you could help clarify this mystery? Afraid there’s no “From” address. It’s the kind of parcel that would add a bit more… quack to someone’s bath times, if you catch my drift.\n\n\n\nYour job is to find out:\n\nAt what type of address did the Devious Delivery end up?\nWhat were the contents of the Devious Delivery?\n\n\n\n\nThe third report of a missing package comes from a grandparent who lives down the street from the post office. They approach your counter and tell you the following:\n\n\n\n\n\n\nOh, excuse me, Clerk. I had sent a mystery gift, you see, to my wonderful granddaughter, off at 728 Maple Place. That was about two weeks ago. Now the delivery date has passed by seven whole days and I hear she still waits, her hands empty and heart filled with anticipation. I’m a bit worried wondering where my package has gone. I cannot for the life of me remember what’s inside, but I do know it’s filled to the brim with my love for her. Can we possibly track it down so it can fill her day with joy? I did send it from my home at 109 Tileston Street.\n\n\n\nYour job is to find out:\n\nWhat are the contents of the Forgotten Gift?\nWho has the Forgotten Gift?"
  },
  {
    "objectID": "projects/SQLPackages/packages.html#problem-1-the-missing-letter",
    "href": "projects/SQLPackages/packages.html#problem-1-the-missing-letter",
    "title": "Using SQL to find the missing packages in the mail delivery service’s database",
    "section": "",
    "text": "The first report of a missing package comes from Anneke. Anneke walks up to your counter and tells you the following:\n\n\n\n\n\n\nClerk, my name’s Anneke. I live over at 900 Somerville Avenue. Not long ago, I sent out a special letter. It’s meant for my friend Varsha. She’s starting a new chapter of her life at 2 Finnegan Street, uptown. (That address, let me tell you: it was a bit tricky to get right the first time.) The letter is a congratulatory note—a cheery little paper hug from me to her, to celebrate this big move of hers. Can you check if it’s made its way to her yet?\n\n\n\nYour job is to find out:\n\nAt what type of address did the Lost Letter end up?\nAt what address did the Lost Letter end up?"
  },
  {
    "objectID": "projects/SQLPackages/packages.html#problem-2-the-devious-delivery",
    "href": "projects/SQLPackages/packages.html#problem-2-the-devious-delivery",
    "title": "Using SQL to find the missing packages in the mail delivery service’s database",
    "section": "",
    "text": "The second report of a missing package comes from a mysterious fellow from out of town. They walk up to your counter and tell you the following:\n\n\n\n\n\n\nGood day to you, deliverer of the mail. You might remember that not too long ago I made my way over from the town of Fiftyville. I gave a certain box into your reliable hands and asked you to keep things low. My associate has been expecting the package for a while now. And yet, it appears to have grown wings and flown away. Ha! Any chance you could help clarify this mystery? Afraid there’s no “From” address. It’s the kind of parcel that would add a bit more… quack to someone’s bath times, if you catch my drift.\n\n\n\nYour job is to find out:\n\nAt what type of address did the Devious Delivery end up?\nWhat were the contents of the Devious Delivery?"
  },
  {
    "objectID": "projects/SQLPackages/packages.html#problem-3-the-forgotten-gift",
    "href": "projects/SQLPackages/packages.html#problem-3-the-forgotten-gift",
    "title": "Using SQL to find the missing packages in the mail delivery service’s database",
    "section": "",
    "text": "The third report of a missing package comes from a grandparent who lives down the street from the post office. They approach your counter and tell you the following:\n\n\n\n\n\n\nOh, excuse me, Clerk. I had sent a mystery gift, you see, to my wonderful granddaughter, off at 728 Maple Place. That was about two weeks ago. Now the delivery date has passed by seven whole days and I hear she still waits, her hands empty and heart filled with anticipation. I’m a bit worried wondering where my package has gone. I cannot for the life of me remember what’s inside, but I do know it’s filled to the brim with my love for her. Can we possibly track it down so it can fill her day with joy? I did send it from my home at 109 Tileston Street.\n\n\n\nYour job is to find out:\n\nWhat are the contents of the Forgotten Gift?\nWho has the Forgotten Gift?"
  },
  {
    "objectID": "projects/Salesdashboard/salesdashboard.html",
    "href": "projects/Salesdashboard/salesdashboard.html",
    "title": "Sales dashboard using Tableau",
    "section": "",
    "text": "In this project, we will build a dashboard using Tableau to help stakeholders analyze sales performance for the years 2020-2023. The dashboard is designed based on the following requirements, and the complete dashboard can be accessed at the following link:\nClick here to view the full dashboard\n\n1 Dashboard Requirements\nSales metrics and trends:\n\nDisplay a summary of sales metrics such as total sales, total profits, and total quantity, comparing the current year with the previous year with KPI symbol.\nFor each sales metric, present the data on a monthly basis, comparing the current year with the previous year. Highlight the highest and lowest months.\n\nProduct subcategory comparison:\n\nCompare sales across different product subcategories for the current year and the previous year.\nCompare sales and profits for the current year.\n\nWeekly trends for sales & profit:\n\nPresent weekly sales and profit data for the current year.\nDisplay the average weekly values for sales and profit data.\nHighlight weeks that are above and below the average values to draw attention.\n\n\n\n2 Design & Interactivity Requirements\n\nMake the graphs interactive, enabling the users to filter the data using graphs.\nThe dashboard should allow users to check historical data by offering them the flexibility to select any desired year.\nAllow users to filter the data by product information like category and subcategory, as well as by location information such as region, state, and city.\n\n\n\n3 Sample GIF of the Dashboard\n\n\n\nGIF of the Dashboard\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/NimGame/NimGame.html",
    "href": "projects/NimGame/NimGame.html",
    "title": "Training an AI to play a game using reinforcement learning",
    "section": "",
    "text": "In this project, we will build an AI to learn the strategy for playing the game Nim through reinforcement learning. In particular, we will explore one of the models of reinforcement learning called Q-learning. But first, let’s look at how the Nim game is played."
  },
  {
    "objectID": "projects/NimGame/NimGame.html#defining-the-nim-game",
    "href": "projects/NimGame/NimGame.html#defining-the-nim-game",
    "title": "Training an AI to play a game using reinforcement learning",
    "section": "3.1 Defining the Nim game",
    "text": "3.1 Defining the Nim game\nThe Nim class defines how a Nim game is played. An object of the Nim class is initialized to keep track of the piles, the current player, and the winner of the game. The available_actions method returns a set of all the available actions for a given state. The move method checks the validity of a player’s move/action, updates the number of objects in the piles according to the move, switches the player’s turn using the switch_player and other_player methods, and finally checks for a winner.\n\n\nCode\n# Import the required modules\n\nimport math\nimport random\nimport time\n\n\nclass Nim():\n    \"\"\" Class to define the Nim game itself \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize game board.\n        Each game board has\n            - `piles`: a list of how many objects remain in each pile\n            - `player`: 0 or 1 to indicate which player's turn\n            - `winner`: None, 0, or 1 to indicate who the winner is\n        \"\"\"\n        initial=[1, 3, 5, 7]\n        self.piles = initial.copy()\n        self.player = 0\n        self.winner = None\n\n    @classmethod\n    def available_actions(cls, piles):\n        \"\"\"\n        Nim.available_actions(piles) takes a `piles` list aka `state` as input\n        and returns all of the available actions `(i, j)` in that state.\n\n        Action `(i, j)` represents the action of removing `j` items\n        from pile `i` (where piles are 0-indexed).\n        \"\"\"\n        actions = set()\n        for i, pile in enumerate(piles):\n            for j in range(1, pile + 1):\n                actions.add((i, j))\n        return actions\n\n    @classmethod\n    def other_player(cls, player):\n        \"\"\"\n        Nim.other_player(player) returns the player that is not\n        `player`. Assumes `player` is either 0 or 1.\n        \"\"\"\n        return 0 if player == 1 else 1\n\n    def switch_player(self):\n        \"\"\"\n        Switch the current player to the other player.\n        \"\"\"\n        self.player = Nim.other_player(self.player)\n\n    def move(self, action):\n        \"\"\"\n        Make the move aka `action` for the current player.\n        `action` must be a tuple `(i, j)`.\n        \"\"\"\n        pile, count = action\n\n        # Check for the validity of the move\n        if self.winner is not None:\n            raise Exception(\"Game already won\")\n        elif pile &lt; 0 or pile &gt;= len(self.piles):\n            raise Exception(\"Invalid pile\")\n        elif count &lt; 1 or count &gt; self.piles[pile]:\n            raise Exception(\"Invalid number of objects\")\n\n        # Update pile\n        self.piles[pile] -= count\n        \n        # Switch the player\n        self.switch_player()\n\n        # Check for a winner\n        if all(pile == 0 for pile in self.piles):\n            self.winner = self.player"
  },
  {
    "objectID": "projects/NimGame/NimGame.html#defining-the-nimai",
    "href": "projects/NimGame/NimGame.html#defining-the-nimai",
    "title": "Training an AI to play a game using reinforcement learning",
    "section": "3.2 Defining the NimAI",
    "text": "3.2 Defining the NimAI\nThe NimAI class defines the AI where the Q-learning algorithm is implemented. An object of the NimAI class is initialized with an empty q_value dictionary, and default values of 0.5 and 0.1 for alpha and epsilon respectively. The q_value dictionary keeps track of all Q-values of (state, action) pairs learned by the AI. Alpha is used in the Q-learning formula, and epsilon is used for action selection.\nThe update method updates the Q-value of an action in a state. It takes inputs: old_state (the state where the action is taken), action (the action taken in the old state), reward (the immediate reward for that action in that state), and new_state (the state resulting from taking that action). The method then implements Q-learning by retrieving the current Q-value using get_q_value, determining the best possible future rewards with best_future_reward, and updating the Q-value using update_q_value.\nLastly, the choose_action method selects an action for a given state based on an epsilon-greedy algorithm. The epsilon-greedy algorithm allows the AI to explore other actions in a state to maximize future rewards. With probability epsilon, the AI chooses a random action (explore), and with probability (1 - epsilon), it chooses the action with the highest Q-value (exploit). This balance between exploration and exploitation helps in improving the AI’s performance over time.\n\n\nCode\nclass NimAI():\n    \"\"\" Class to define the AI \"\"\"\n    def __init__(self, alpha=0.5, epsilon=0.1):\n        \"\"\"\n        Initialize AI with an empty Q-learning dictionary,\n        an alpha (learning) rate, and an epsilon rate.\n\n        The Q-learning dictionary maps `(state, action)` pairs to a Q-value (a number).\n         - `state` is a tuple of remaining piles, e.g. (1, 1, 4, 4)\n         - `action` is a tuple `(i, j)` for an action\n        \"\"\"\n        self.q_value = {}\n        self.alpha = alpha\n        self.epsilon = epsilon\n\n    def update(self, old_state, action, new_state, reward):\n        \"\"\"\n        Update Q-learning model, given an old state, an action taken\n        in that state, a new resulting state, and the reward received\n        from taking that action.\n        \"\"\"\n        old = self.get_q_value(old_state, action)\n        best_future = self.best_future_reward(new_state)\n        self.update_q_value(old_state, action, old, reward, best_future)\n\n    def get_q_value(self, state, action):\n        \"\"\"\n        Return the Q-value for the state `state` and the action `action`.\n        If no Q-value exists yet in `self.q`, return 0.\n        \"\"\"\n        # If there is a Q-value for current (state, action)\n        # already in `self.q`, return it\n        if (tuple(state), action) in self.q_value:\n            return self.q_value[(tuple(state), action)]\n\n        # If current (state action) is not explored yet, Q-value is 0\n        return 0\n\n    def update_q_value(self, state, action, old_q, reward, future_rewards):\n        \"\"\"\n        Update the Q-value for the state `state` and the action `action`\n        given the previous Q-value `old_q`, a current reward `reward`,\n        and an estiamte of future rewards `future_rewards`.\n\n        Use the formula:\n\n        Q(s, a) &lt;- old value estimate + alpha * (new value estimate - old value estimate)\n\n        where `old value estimate` is the previous Q-value,\n        `alpha` is the learning rate, and `new value estimate`\n        is the sum of the current reward and estimated future rewards.\n        \"\"\"\n        # Calculate and get constants\n        new_value_estimate = reward + future_rewards\n        alpha = self.alpha\n\n        # Update Q-value according to the formula\n        self.q_value[(tuple(state), action)] = old_q + alpha * (new_value_estimate - old_q)\n\n    def best_future_reward(self, state):\n        \"\"\"\n        Given a state `state`, consider all possible `(state, action)`\n        pairs available in that state and return the maximum of all\n        of their Q-values.\n\n        Use 0 as the Q-value if a `(state, action)` pair has no\n        Q-value in `self.q`. If there are no available actions in\n        `state`, return 0.\n        \"\"\"\n        possible_actions = Nim.available_actions(state)\n\n        # Corner case where there is no possible actions\n        if len(possible_actions) == 0:\n            return 0\n\n        # Initialize cur_reward to as low as possible to make sure\n        # There are better actions than None\n        reward = -math.inf\n\n        for action in possible_actions:\n            # If action is in self.q and the reward of the action \n            # is better than current reward, update reward\n            cur_reward = self.get_q_value(state, action)\n            if cur_reward &gt; reward:\n                reward = cur_reward\n\n        return reward\n\n    def choose_action(self, state, epsilon=True):\n        \"\"\"\n        Given a state `state`, return an action `(i, j)` to take.\n\n        If `epsilon` is `False`, then return the best action\n        available in the state (the one with the highest Q-value,\n        using 0 for pairs that have no Q-values).\n\n        If `epsilon` is `True`, then with probability\n        `self.epsilon` choose a random available action,\n        otherwise choose the best action available.\n\n        If multiple actions have the same Q-value, any of those\n        options is an acceptable return value.\n        \"\"\"\n        # Initialize all possible actions\n        # Set highest Q-value to as low as possible to make sure\n        # some action has better  Q-value than the initial best action of None\n        possible_actions = Nim.available_actions(state)\n        highest_q = -math.inf \n        best_action = None    \n\n        # Iterate all possible actions and compare the Q-value of each\n        for action in possible_actions:\n            current_q = self.get_q_value(state, action)\n            # If current action is better, update current Q-value and best_action\n            if current_q &gt; highest_q:\n                highest_q = current_q\n                best_action = action\n\n        # If epsilon is true, take random action according to probabilities\n        # Exploration vs Exploitation\n        if epsilon:\n            # For self.epsilon chance, take random action\n            # For 1 - self.epsilon chance, take best action\n            action_weights = [self.epsilon / len(possible_actions) if action != best_action else\n                                (1 - self.epsilon) for action in possible_actions]\n\n            best_action = random.choices(list(possible_actions), weights=action_weights, k=1)[0]\n\n        return best_action"
  },
  {
    "objectID": "projects/NimGame/NimGame.html#defining-the-training",
    "href": "projects/NimGame/NimGame.html#defining-the-training",
    "title": "Training an AI to play a game using reinforcement learning",
    "section": "3.3 Defining the training",
    "text": "3.3 Defining the training\nThe train function trains the AI by making it play against itself ‘n’ times. It sets up the game using Nim class, trains the AI using NimAI class, and finally returns the trained AI.\n\n\nCode\ndef train(n):\n    \"\"\"\n    Train an AI by playing `n` games against itself.\n    \"\"\"\n\n    player = NimAI()\n\n    # Play 'n' games\n    for i in range(n):\n        \n        # print the phrase only for the first and last 10 games when training is &gt; 50 games\n        if i+1 &lt;= 10 or n &lt;=50:\n            print(f\"Playing training game {i + 1}\")\n            \n        elif len(range(n)) - i &lt;= 10 :\n            if len(range(n)) - i == 10:\n                print(\"*\\n\"*5 , end='')\n            print(f\"Playing training game {i + 1}\")\n\n\n        #initialize the game\n        game = Nim()\n\n        # Keep track of last move made by either player\n        last = {\n            0: {\"state\": None, \"action\": None},\n            1: {\"state\": None, \"action\": None}\n        }\n\n        # Game loop\n        while True:\n\n            # Keep track of current state and action\n            state = game.piles.copy()\n            action = player.choose_action(game.piles)\n\n            # Keep track of last state and action\n            last[game.player][\"state\"] = state\n            last[game.player][\"action\"] = action\n\n            # Make move\n            game.move(action)\n            new_state = game.piles.copy()\n\n            # When game is over, update Q-value with rewards\n            if game.winner is not None:\n\n                # update the state and action that resulted in loss with reward value -1\n                player.update(state, action, new_state, -1)\n\n                # update the state and action that resulted in win with reward value 1\n                player.update(last[game.player][\"state\"], last[game.player][\"action\"], new_state, 1)\n                \n                break\n\n            # If game is continuing, update Q-value with no rewards i.e. 0\n            elif last[game.player][\"state\"] is not None:\n\n                player.update(last[game.player][\"state\"],last[game.player][\"action\"], new_state, 0)\n\n    print(\"\\nDone training\")\n\n    # Return the trained AI\n    return player"
  },
  {
    "objectID": "projects/NimGame/NimGame.html#defining-the-play-between-a-human-and-the-nimai",
    "href": "projects/NimGame/NimGame.html#defining-the-play-between-a-human-and-the-nimai",
    "title": "Training an AI to play a game using reinforcement learning",
    "section": "3.4 Defining the play between a human and the NimAI",
    "text": "3.4 Defining the play between a human and the NimAI\nThe play function sets up a Nim game between a human and the AI using the NimAI object.\n\n\nCode\ndef play(nim_ai, human_player=None):\n    \"\"\"\n    Play human game against the AI.\n    `human_player` can be set to 0 or 1 to specify whether\n    human player moves first or second.\n    \"\"\"\n\n    # If no player order set, choose human's order randomly\n    if human_player is None:\n        human_player = random.randint(0, 1)\n\n    # Create new game\n    game = Nim()\n\n    # Game loop\n    while True:\n\n        # Print contents of piles\n        print()\n        print(\"Piles:\")\n        for i, pile in enumerate(game.piles):\n            print(f\"Pile {i}: {pile}\")\n        print()\n\n        # Compute current available actions\n        available_actions = Nim.available_actions(game.piles)\n        time.sleep(1)\n\n        # Let human make a move\n        if game.player == human_player:\n            print(\"Your Turn\")\n            while True:\n                pile = int(input(\"Choose Pile: \"))\n                count = int(input(\"Choose Count: \"))\n                if (pile, count) in available_actions:\n                    break\n                print(\"Invalid move, try again.\")\n\n        # Have AI make a move \n        else:\n            print(\"AI's Turn\")\n            pile, count = nim_ai.choose_action(game.piles, epsilon=False)\n            print(f\"AI chose to take {count} object(s) from pile {pile}.\")\n\n        # updates the objects in each pile after taking action; Switches player; Checks for winner\n        game.move((pile, count))\n\n        # Checks for winner and ends the game\n        if game.winner is not None:\n            print()\n            print(\"GAME OVER\")\n            winner = \"Human\" if game.winner == human_player else \"AI\"\n            print(f\"Winner is {winner}\")\n            return"
  },
  {
    "objectID": "projects/NimGame/NimGame.html#human-vs-untrained-ai",
    "href": "projects/NimGame/NimGame.html#human-vs-untrained-ai",
    "title": "Training an AI to play a game using reinforcement learning",
    "section": "4.1 Human Vs Untrained AI",
    "text": "4.1 Human Vs Untrained AI\n\n\nCode\nuntrained_ai = train(0)\n\n\nDone training\n\n\nCode\n# start a Nim game between human and untrained AI\nplay(untrained_ai)\n\n\nPiles:\nPile 0: 1\nPile 1: 3\nPile 2: 5\nPile 3: 7\n\nYour Turn\nChoose Pile: 2\nChoose Count: 5\n\nPiles:\nPile 0: 1\nPile 1: 3\nPile 2: 0\nPile 3: 7\n\nAI's Turn\nAI chose to take 1 object(s) from pile 0.\n\nPiles:\nPile 0: 0\nPile 1: 3\nPile 2: 0\nPile 3: 7\n\nYour Turn\nChoose Pile: 3\nChoose Count: 6\n\nPiles:\nPile 0: 0\nPile 1: 3\nPile 2: 0\nPile 3: 1\n\nAI's Turn\nAI chose to take 1 object(s) from pile 3.\n\nPiles:\nPile 0: 0\nPile 1: 3\nPile 2: 0\nPile 3: 0\n\nYour Turn\nChoose Pile: 1\nChoose Count: 2\n\nPiles:\nPile 0: 0\nPile 1: 1\nPile 2: 0\nPile 3: 0\n\nAI's Turn\nAI chose to take 1 object(s) from pile 1.\n\nGAME OVER\nWinner is Human\nWe can see that it is very easy to win against the AI since it is playing randomly without using any optimized Q-values."
  },
  {
    "objectID": "projects/NimGame/NimGame.html#human-vs-trained-ai",
    "href": "projects/NimGame/NimGame.html#human-vs-trained-ai",
    "title": "Training an AI to play a game using reinforcement learning",
    "section": "4.2 Human Vs Trained AI",
    "text": "4.2 Human Vs Trained AI\nNow, let’s train our AI on 10,000 games and play against it.\n\n\nCode\ntrained_ai = train(10000)\n\n\nPlaying training game 1\nPlaying training game 2\nPlaying training game 3\nPlaying training game 4\nPlaying training game 5\nPlaying training game 6\nPlaying training game 7\nPlaying training game 8\nPlaying training game 9\nPlaying training game 10\n*\n*\n*\n*\n*\nPlaying training game 9991\nPlaying training game 9992\nPlaying training game 9993\nPlaying training game 9994\nPlaying training game 9995\nPlaying training game 9996\nPlaying training game 9997\nPlaying training game 9998\nPlaying training game 9999\nPlaying training game 10000\n\nDone training\n\n\nCode\n# start a Nim game between human and trained AI\nplay(trained_ai)\n\n\nPiles:\nPile 0: 1\nPile 1: 3\nPile 2: 5\nPile 3: 7\n\nAI's Turn\nAI chose to take 5 object(s) from pile 2.\n\nPiles:\nPile 0: 1\nPile 1: 3\nPile 2: 0\nPile 3: 7\n\nYour Turn\nChoose Pile: 1\nChoose Count: 2\n\nPiles:\nPile 0: 1\nPile 1: 1\nPile 2: 0\nPile 3: 7\n\nAI's Turn\nAI chose to take 6 object(s) from pile 3.\n\nPiles:\nPile 0: 1\nPile 1: 1\nPile 2: 0\nPile 3: 1\n\nYour Turn\nChoose Pile: 3\nChoose Count: 1\n\nPiles:\nPile 0: 1\nPile 1: 1\nPile 2: 0\nPile 3: 0\n\nAI's Turn\nAI chose to take 1 object(s) from pile 0.\n\nPiles:\nPile 0: 0\nPile 1: 1\nPile 2: 0\nPile 3: 0\n\nYour Turn\nChoose Pile: 1\nChoose Count: 1\n\nGAME OVER\nWinner is AI\nNow that we have trained the AI, we can see that it is quite challenging to beat the AI as it has gained the experience needed to make optimal moves and win the game."
  },
  {
    "objectID": "projects/FashionMNIST/fashionMNIST.html",
    "href": "projects/FashionMNIST/fashionMNIST.html",
    "title": "Building a model to identify the type of clothing in the image",
    "section": "",
    "text": "This will be published by 27.08.2024\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/Bert/bertmodel.html",
    "href": "projects/Bert/bertmodel.html",
    "title": "Using a pre-trained BERT model for text prediction and analysing its self-attention scores",
    "section": "",
    "text": "BERT (Bidirectional Encoder Representations from Transformers) is a pre-trained transformer-based model designed for various NLP tasks, including masked language modeling. In masked language modeling, BERT predicts missing or masked words within a text sequence by leveraging the surrounding context. The transformer architecture it uses consists of multiple layers of self-attention mechanisms and feedforward neural networks, which enable it to understand and model complex language patterns. The base BERT model contains 12 transformer layers (also known as transformer blocks), each with 12 self-attention heads, totaling 144 self-attention heads across the model.\nIn this project, we will:"
  },
  {
    "objectID": "projects/Bert/bertmodel.html#import-the-required-modules",
    "href": "projects/Bert/bertmodel.html#import-the-required-modules",
    "title": "Using a pre-trained BERT model for text prediction and analysing its self-attention scores",
    "section": "1.1 Import the required modules",
    "text": "1.1 Import the required modules\n\n\nCode\n# Import the required modules\n\nimport os\nimport sys\nimport torch\nfrom PIL import Image, ImageDraw, ImageFont\nfrom transformers import BertTokenizer, BertForMaskedLM\n\n\nWe will utilize the transformers library from Hugging Face, which provides pre-trained models and tokenizers for a variety of NLP tasks. Specifically, BertTokenizer is used to convert text into tokens that the BERT model can process, while BertForMaskedLM is the version of BERT specialized for masked language modeling."
  },
  {
    "objectID": "projects/Bert/bertmodel.html#setup-constants",
    "href": "projects/Bert/bertmodel.html#setup-constants",
    "title": "Using a pre-trained BERT model for text prediction and analysing its self-attention scores",
    "section": "1.2 Setup constants",
    "text": "1.2 Setup constants\n\n\nCode\n# Pre-trained masked language model\nMODEL = \"bert-base-uncased\"\n\n# Number of predictions to generate\nK = 3\n\n# Constants for generating attention diagrams\nFONT_PATH = \"OpenSans-Regular.ttf\"\nGRID_SIZE = 40\nPIXELS_PER_WORD = 200\n\n# Load the font\ntry:\n    FONT = ImageFont.truetype(FONT_PATH, 28)\nexcept IOError:\n    print(f\"Font not found at {FONT_PATH}. Loading default font\")\n    FONT = ImageFont.load_default()\n\n\nWe are using the bert-base-uncased version of BERT, where all text is converted to lowercase before tokenization, meaning no distinction is made between uppercase and lowercase letters. The constant K represents the number of top predictions the model should return for a masked word. This involves ranking potential words that could replace the [MASK] token and selecting the top K candidates."
  },
  {
    "objectID": "projects/Bert/bertmodel.html#the-main-function",
    "href": "projects/Bert/bertmodel.html#the-main-function",
    "title": "Using a pre-trained BERT model for text prediction and analysing its self-attention scores",
    "section": "1.3 The main() function",
    "text": "1.3 The main() function\n\n\nCode\ndef main(text, viz_attentions = False):\n\n    # Tokenize input\n    tokenizer = BertTokenizer.from_pretrained(MODEL)\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    mask_token_index = get_mask_token_index(tokenizer.mask_token_id, inputs)\n    if mask_token_index is None:\n        sys.exit(f\"Input must include mask token {tokenizer.mask_token}.\")\n\n    # Use model to process input\n    model = BertForMaskedLM.from_pretrained(MODEL)\n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():  # Disable gradient computation\n        result = model(**inputs, output_attentions=True)\n\n    # Generate predictions\n    mask_token_logits = result.logits[0, mask_token_index]\n    top_tokens = torch.topk(mask_token_logits, K).indices\n    for token in top_tokens:\n        print(text.replace(tokenizer.mask_token, tokenizer.decode([token])))\n\n    # Visualize attentions\n    if viz_attentions:\n        visualize_attentions(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]), result.attentions)\n\n\nNow, let’s briefly go over some important parts of the code and explain the underlying concepts:\nThe main() function:\nThis is where the script’s logic begins. The function must be called with a sentence containing a masked token ([MASK]). The masked token is crucial because BERT’s masked language modeling task involves predicting the masked word using the surrounding context.\nTokenization:\nThe input text is tokenized using the BERT tokenizer. Tokenization breaks the text into tokens (words or subwords) that the model can process. BERT uses WordPiece tokenization, which allows it to handle words and subwords. The argument return_tensors=\"pt\" ensures that the tokenized output is returned as PyTorch tensors, which are the primary data structures used by models in PyTorch. The get_mask_token_index() function finds the index of the [MASK] token in the tokenized input. This index is critical because the model predicts the missing word at this position.\nModel Inference:\nThe BERT model processes the tokenized inputs. It returns several outputs, including logits (which contain predictions for the masked token) and attentions (which contain the self-attention scores from each layer of the model). The output_attentions=True argument ensures that attention scores are included in the output.\nGenerating Predictions:\nThe script extracts the logits corresponding to the masked token. Logits are raw, unnormalized scores output by the model, representing its confidence in each possible token being the correct replacement for the [MASK] position. torch.topk is then used to select the top K highest-scoring tokens from the logits. These tokens are the model’s most likely candidates to replace the [MASK]. The top predicted tokens are decoded back into words or subwords using tokenizer.decode(). The original text is then printed with the [MASK] token replaced by each predicted token, showing what the model considers the most likely words in the given context.\nVisualizing Attention Scores:\nThe token IDs are converted back to their corresponding tokens (words or subwords) using tokenizer.convert_ids_to_tokens(). This is necessary because attention scores are tied to specific tokens, which need to be displayed in the visualization. The visualize_attentions() function is called to generate diagrams that represent the attention scores across different layers and heads in the BERT model."
  },
  {
    "objectID": "projects/Bert/bertmodel.html#helper-functions",
    "href": "projects/Bert/bertmodel.html#helper-functions",
    "title": "Using a pre-trained BERT model for text prediction and analysing its self-attention scores",
    "section": "1.4 Helper functions",
    "text": "1.4 Helper functions\nNow, let’s go over the helper functions that are used in the main() function.\n\n\nCode\ndef get_mask_token_index(mask_token_id, inputs):\n    \"\"\"\n    Return the index of the token with the specified `mask_token_id`, or\n    `None` if not present in the `inputs`.\n    \"\"\"\n    for i, token in enumerate(inputs['input_ids'][0]):\n        if token == mask_token_id:\n            return i\n    return None\n\n\nThe get_mask_token_index() function returns the index of the masked token in the input sequence. If the token is not found, it returns None.\n\n\nCode\ndef get_color_for_attention_score(attention_score):\n    \"\"\"\n    Return a tuple of three integers representing a shade of gray for the\n    given `attention_score`. Each value should be in the range [0, 255].\n    \"\"\"\n    return (round(attention_score * 255), round(attention_score * 255), round(attention_score * 255))\n\n\nThe get_color_for_attention_score() function converts an attention score (ranging from 0 to 1) into a grayscale color tuple, where higher scores correspond to lighter shades.\n\n\nCode\ndef generate_diagram(layer_number, head_number, tokens, attention_weights):\n    \"\"\"\n    Generate a diagram representing the self-attention scores for a single\n    attention head. The diagram shows one row and column for each of the\n    `tokens`, and cells are shaded based on `attention_weights`, with lighter\n    cells corresponding to higher attention scores.\n\n    The diagram is saved with a filename that includes both the `layer_number`\n    and `head_number`.\n    \"\"\"\n    # Create new image\n    image_size = GRID_SIZE * len(tokens) + PIXELS_PER_WORD\n    img = Image.new(\"RGBA\", (image_size, image_size), \"black\")\n    draw = ImageDraw.Draw(img)\n\n    # Draw each token onto the image\n    for i, token in enumerate(tokens):\n        # Draw token columns\n        token_image = Image.new(\"RGBA\", (image_size, image_size), (0, 0, 0, 0))\n        token_draw = ImageDraw.Draw(token_image)\n        token_draw.text(\n            (image_size - PIXELS_PER_WORD, PIXELS_PER_WORD + i * GRID_SIZE),\n            token,\n            fill=\"white\",\n            font=FONT\n        )\n        token_image = token_image.rotate(90)\n        img.paste(token_image, mask=token_image)\n\n        # Draw token rows\n        _, _, width, _ = draw.textbbox((0, 0), token, font=FONT)\n        draw.text(\n            (PIXELS_PER_WORD - width, PIXELS_PER_WORD + i * GRID_SIZE),\n            token,\n            fill=\"white\",\n            font=FONT\n        )\n\n    # Draw each word\n    for i in range(len(tokens)):\n        y = PIXELS_PER_WORD + i * GRID_SIZE\n        for j in range(len(tokens)):\n            x = PIXELS_PER_WORD + j * GRID_SIZE\n            color = get_color_for_attention_score(attention_weights[i][j].item())\n            draw.rectangle((x, y, x + GRID_SIZE, y + GRID_SIZE), fill=color)\n\n    # Save image in Attention images folder\n    Attention_folder_path = os.path.join(os.getcwd(), 'Attention images')\n    if not os.path.exists(Attention_folder_path):\n        os.makedirs(Attention_folder_path)\n\n    img.save(f\"{Attention_folder_path}/Attention_Layer{layer_number}_Head{head_number}.png\")\n\n\nThe generate_diagram() function generates an image visualizing the self-attention scores for a single attention head. It creates a grid where each cell is shaded based on the attention score between two tokens. The diagram is saved as an image file in the “Attention images” folder.\n\n\nCode\ndef visualize_attentions(tokens, attentions):\n    \"\"\"\n    Produce a graphical representation of self-attention scores.\n\n    For each attention layer, one diagram should be generated for each\n    attention head in the layer. Each diagram should include the list of\n    `tokens` in the sentence. The filename for each diagram should\n    include both the layer number (starting count from 1) and head number\n    (starting count from 1).\n    \"\"\"\n    # BERT's attentions are stored per-layer, per-head, and across the token sequence\n    for i, layer in enumerate(attentions):\n        # attentions are: batch_size x num_heads x seq_length x seq_length\n        for k, head_attention in enumerate(layer[0]):\n            layer_number = i + 1\n            head_number = k + 1\n            generate_diagram(\n                layer_number,\n                head_number,\n                tokens,\n                head_attention\n            )\n\n\nThe visualize_attentions() function orchestrates the generation of attention diagrams for all layers and heads of the BERT model. It iterates over the attention layers and heads, calling generate_diagram() to create and save an attention diagram for each head in each layer."
  },
  {
    "objectID": "projects/Bert/bertmodel.html#layer-1-head-5",
    "href": "projects/Bert/bertmodel.html#layer-1-head-5",
    "title": "Using a pre-trained BERT model for text prediction and analysing its self-attention scores",
    "section": "3.1 Layer 1, Head 5",
    "text": "3.1 Layer 1, Head 5\n\n\n\nAttention Layer1 Head5\n\n\nIn this diagram, we can see that the word ‘he’ is paying attention to the word ‘went’, which might indicate that this attention head is exploring the relationship between the subject and the verb."
  },
  {
    "objectID": "projects/Bert/bertmodel.html#layer-5-head-1",
    "href": "projects/Bert/bertmodel.html#layer-5-head-1",
    "title": "Using a pre-trained BERT model for text prediction and analysing its self-attention scores",
    "section": "3.2 Layer 5, Head 1",
    "text": "3.2 Layer 5, Head 1\n\n\n\nAttention Layer5 Head1\n\n\nHere we can see that the words ‘went’, ‘get’, and ‘some’ are attending to the word ‘supermarket’, which might indicate that the model is trying to understand the context of where the action is taking place, which is crucial for predicting what the person is going to get."
  },
  {
    "objectID": "projects/Bert/bertmodel.html#layer-12-head-8",
    "href": "projects/Bert/bertmodel.html#layer-12-head-8",
    "title": "Using a pre-trained BERT model for text prediction and analysing its self-attention scores",
    "section": "3.3 Layer 12, Head 8",
    "text": "3.3 Layer 12, Head 8\n\n\n\nAttention Layer12 Head8\n\n\nIn this case, the [MASK] token is attending to the words ‘supermarket,’ ‘get,’ and ‘some’, which might indicate that the model is trying to determine what the missing word should be based on the context of these words."
  },
  {
    "objectID": "projects/Bert/bertmodel.html#diagonal-patterns",
    "href": "projects/Bert/bertmodel.html#diagonal-patterns",
    "title": "Using a pre-trained BERT model for text prediction and analysing its self-attention scores",
    "section": "3.4 Diagonal patterns",
    "text": "3.4 Diagonal patterns\nThe following heads have show strong attention along the diagonal which indicate that they are focusing on local context and syntactic relationships, ensuring that each word’s immediate context is well-understood.\n\n3.4.1 Layer 3, Head 1\n\n\n\nAttention Layer3 Head1\n\n\nHere, we can see that each word is paying attention to the word that immediately follows it.\n\n\n3.4.2 Layer 3, Head 7\n\n\n\nAttention Layer3 Head7\n\n\nIn this case, each word is focusing on itself.\n\n\n3.4.3 Layer 4, Head 6\n\n\n\nAttention Layer4 Head6\n\n\nHere, we can see that each word is attending to the word that precedes it."
  },
  {
    "objectID": "projects/BnMclass/binaryNmulti.html",
    "href": "projects/BnMclass/binaryNmulti.html",
    "title": "Developing neural network models for classification problems using PyTorch",
    "section": "",
    "text": "In this project, we are going to explore how to use PyTorch to solve classification problems, specifically binary and multi-class classification problems. To achieve this, we will utilize the built-in datasets from the scikit-learn module and perform modeling using PyTorch.\nWe will follow these steps:\nLet’s first look at the binary classification problem, and then move on to the multi-class classification problem."
  },
  {
    "objectID": "projects/BnMclass/binaryNmulti.html#prepare-and-explore-the-data",
    "href": "projects/BnMclass/binaryNmulti.html#prepare-and-explore-the-data",
    "title": "Developing neural network models for classification problems using PyTorch",
    "section": "1.1 Prepare and explore the data",
    "text": "1.1 Prepare and explore the data\nTo demonstrate the binary classification problem, we will use the make_circles() method from scikit-learn to generate two circles with differently colored dots.\n\n\nCode\n# Make 1000 samples\nn_samples = 1000\n\n# Create circles\nX, y = make_circles(n_samples, noise=0.03, random_state=42)\n\n\nNow, let’s explore our dataset.\n\n\nCode\n# Check the dimensions of our features and labels\n\nprint(f\"The dimension of feature X: {X.ndim}\")\nprint(f\"The dimension of label y: {y.ndim}\", end = '\\n\\n')\n\n# Check the shapes of our features and labels\n\nprint(f\"The shape of feature X: {X.shape}\")\nprint(f\"The shape of label y: {y.shape}\", end = '\\n\\n') # y is a scalar\n\n# View the first example of features and labels\n\nprint(f\"Values for FIRST sample of X: {X[0]} and the same for y: {y[0]}\")\nprint(f\"Shapes for FIRST sample of X: {X[0].shape} and the same for y: {y[0].shape}\", end = '\\n\\n')\n\n# Count no. of samples per label\n\nunique_values, counts = np.unique(y, return_counts=True)\nunique_counts_dict = {f'Label {val}': f'{count} samples' for val, count in zip(unique_values, counts)}\nprint(unique_counts_dict, end = '\\n\\n')\n\n# View first five samples\n\nprint(f\"First five X features:\\n{X[:5]}\")\nprint(f\"\\nFirst five corresponding y labels:\\n{y[:5]}\", end = '\\n\\n')\n\n\nThe dimension of feature X: 2\nThe dimension of label y: 1\n\nThe shape of feature X: (1000, 2)\nThe shape of label y: (1000,)\n\nValues for FIRST sample of X: [0.75424625 0.23148074] and the same for y: 1\nShapes for FIRST sample of X: (2,) and the same for y: ()\n\n{'Label 0': '500 samples', 'Label 1': '500 samples'}\n\nFirst five X features:\n[[ 0.75424625  0.23148074]\n [-0.75615888  0.15325888]\n [-0.81539193  0.17328203]\n [-0.39373073  0.69288277]\n [ 0.44220765 -0.89672343]]\n\nFirst five corresponding y labels:\n[1 1 1 1 0]\nFrom the above results, we can see that there are 1000 samples of feature vector X with a dimension of 2 corresponding to 1000 samples of scalar label y with a dimension of 1. This means each pair of X features (say X1 and X2) has one corresponding label y, which is a scalar that is either 0 or 1. Therefore, we have two inputs for one output. Notice that we also have a balanced dataset, i.e., 500 samples per each label.\nNow let’s visualize the dataset.\n\n\nCode\n# Visualize dataset with a plot\n\nplt.figure(figsize=(5, 5))\nplt.scatter(x=X[:, 0], y=X[:, 1], c=y, cmap=plt.cm.RdYlBu)\n\nplt.title(\"Circles Dataset\")\nplt.xlabel(\"Feature 1\")\nplt.ylabel(\"Feature 2\")\nplt.show()\n\n\n\nNow, let’s find out how we could build a neural network using PyTorch to classify the dots into red (0) or blue (1), given X1 and X2 (x-axis and y-axis in the above plot). But, before proceeding to build the PyTorch model, we must first convert our data into tensors and split it into 80% training and 20% testing datasets.\n\n\nCode\n# Turn the data into tensors\n\nX = torch.tensor(X, dtype=torch.float)\ny = torch.tensor(y, dtype=torch.float)\n\n\n\n\nCode\n# Split data into train and test sets\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Number of training and testing samples\n\nprint(f\"Number of training samples: {len(X_train)}\")\nprint(f\"Number of testing samples: {len(X_test)}\")\n\n\nNumber of training samples: 800\nNumber of testing samples: 200"
  },
  {
    "objectID": "projects/BnMclass/binaryNmulti.html#build-the-model",
    "href": "projects/BnMclass/binaryNmulti.html#build-the-model",
    "title": "Developing neural network models for classification problems using PyTorch",
    "section": "1.2 Build the model",
    "text": "1.2 Build the model\nNow that we have our data ready, let’s build our model using PyTorch.\nSince our data is not linearly separable, we will use a non-linear activation function such as ReLU in the model.\n\n\nCode\n# Construct the model\n\nclass CircleModel(nn.Module):\n\n    def __init__(self, hidden_units=10):\n        super().__init__()\n        self.layer_1 = nn.Linear(2, hidden_units)\n        self.layer_2 = nn.Linear(hidden_units, hidden_units)\n        self.layer_3 = nn.Linear(hidden_units, 1)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.relu(self.layer_1(x))\n        x = self.relu(self.layer_2(x))\n        return self.layer_3(x)"
  },
  {
    "objectID": "projects/BnMclass/binaryNmulti.html#train-and-evaluate-the-model",
    "href": "projects/BnMclass/binaryNmulti.html#train-and-evaluate-the-model",
    "title": "Developing neural network models for classification problems using PyTorch",
    "section": "1.3 Train and evaluate the model",
    "text": "1.3 Train and evaluate the model\nNow, let’s define train_and_evaluate() function to train and evaluate the model. This function trains the model for a specified number of epochs, computes training and testing loss and accuracy, and prints the results every 100 epochs.\nThe PyTorch training loop typically contains the following steps:\n\nForward pass - The model takes X_train as input, performs forward() function calculations, and then outputs raw prediction scores (logits) (y_logits = model(X_train).squeeze()). These logits are then converted into prediction probabilities by the sigmoid activation function. Finally, we round the probabilities to 0 or 1 according to the set threshold (here we use 0.5) to get binary predictions (y_pred = torch.round(torch.sigmoid(y_logits)).\nCalculate the loss - The model’s outputs (predictions) are compared to the actual values and evaluated to see how wrong they are (loss_fn(y_pred, y_train)).\nZero the gradients - Clears the gradients of all model parameters, resetting them to zero. This is necessary because gradients accumulate by default in PyTorch (optimizer.zero_grad()).\nPerform backpropagation - Performs backpropagation, calculating the gradient of the loss with respect to each model parameter (loss.backward()).\nStep the optimizer (gradient descent) - Updates the model parameters using the gradients computed in the backward pass (optimizer.step()).\n\nIn the evaluation loop, we use testing data to evaluate the performance of the model by computing the model’s predictions (logits) on the test data, converting the logits to probabilities, and then to binary predictions, similar to the training loop.\n\n\nCode\ndef train_and_evaluate(model, X_train, y_train, X_test, y_test, loss_fn, optimizer, epochs, device='cpu'):\n\n    # Ensure the model is on the correct device\n    model.to(device)\n\n    # Move data to the device\n    X_train, y_train = X_train.to(device), y_train.to(device)\n    X_test, y_test = X_test.to(device), y_test.to(device)\n\n    for epoch in range(epochs):\n\n        ## Training\n\n        # Forward pass\n        y_logits = model(X_train).squeeze()\n        y_pred = torch.round(torch.sigmoid(y_logits))\n\n        # Calculate loss and accuracy\n        loss = loss_fn(y_logits, y_train) # BCEWithLogitsLoss calculates loss using logits\n        acc = accuracy_fn(y_true=y_train, y_pred=y_pred)\n\n        # Optimizer zero grad\n        optimizer.zero_grad()\n\n        # Calculate the Loss\n        loss.backward()\n\n        # Optimizer step\n        optimizer.step()\n\n        ## Testing\n\n        model.eval()\n        with torch.no_grad():\n            # Forward pass\n            test_logits = model(X_test).squeeze()\n            test_pred = torch.round(torch.sigmoid(test_logits)) # logits -&gt; prediction probabilities -&gt; prediction labels\n\n            # Calculate loss and accuracy\n            test_loss = loss_fn(test_logits, y_test)\n            test_acc = accuracy_fn(y_true=y_test, y_pred=test_pred)\n\n        # Print out what's happening\n        if epoch % 100 == 0:\n            print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%\")\n\n\n\n1.3.1 Define accuracy function\nSince our dataset is a balanced dataset, in addition to the loss evaluation metric, we’ll also use the accuracy evaluation metric. Accuracy measures the proportion of correctly classified samples out of the total number of samples. We define a function called accuracy_fn() to perform this task.\n\n\nCode\n# Calculate accuracy\n\ndef accuracy_fn(y_true, y_pred):\n    correct = torch.eq(y_true, y_pred).sum().item()\n    return (correct / len(y_pred)) * 100\n\n\n\n\n1.3.2 Setup loss and optimizer\nSince we are doing binary classification, we can either use torch.nn.BCELossWithLogits or torch.nn.BCELoss as our loss function. Let’s use torch.nn.BCELossWithLogits for this simple problem as it has a built-in sigmoid activation and is also more numerically stable than torch.nn.BCELoss. As for the optimizer, let’s use torch.optim.SGD() to optimize the model parameters with a learning rate of 0.1.\nLet’s first set up device-agnostic code and then instantiate the model.\n\n\nCode\n# Set random seed for reproducibility\ntorch.manual_seed(42)\n\n# Setup device agnostic code\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Instantiate the model\nmodel = CircleModel().to(device)\n\n# Setup loss function\nloss_fn = nn.BCEWithLogitsLoss()  # BCEWithLogitsLoss includes sigmoid\n\n# Setup optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n\n\nNow let’s train and evaluate the model using the above-defined train_and_evaluate() function for 1000 epochs.\n\n\nCode\ntrain_and_evaluate(model, X_train, y_train, X_test, y_test, loss_fn, optimizer, epochs=1000, device=device)\n\n\nEpoch: 0 | Loss: 0.69295, Accuracy: 50.00% | Test Loss: 0.69319, Test Accuracy: 50.00%\nEpoch: 100 | Loss: 0.69115, Accuracy: 52.88% | Test Loss: 0.69102, Test Accuracy: 52.50%\nEpoch: 200 | Loss: 0.68977, Accuracy: 53.37% | Test Loss: 0.68940, Test Accuracy: 55.00%\nEpoch: 300 | Loss: 0.68795, Accuracy: 53.00% | Test Loss: 0.68723, Test Accuracy: 56.00%\nEpoch: 400 | Loss: 0.68517, Accuracy: 52.75% | Test Loss: 0.68411, Test Accuracy: 56.50%\nEpoch: 500 | Loss: 0.68102, Accuracy: 52.75% | Test Loss: 0.67941, Test Accuracy: 56.50%\nEpoch: 600 | Loss: 0.67515, Accuracy: 54.50% | Test Loss: 0.67285, Test Accuracy: 56.00%\nEpoch: 700 | Loss: 0.66659, Accuracy: 58.38% | Test Loss: 0.66322, Test Accuracy: 59.00%\nEpoch: 800 | Loss: 0.65160, Accuracy: 64.00% | Test Loss: 0.64757, Test Accuracy: 67.50%\nEpoch: 900 | Loss: 0.62362, Accuracy: 74.00% | Test Loss: 0.62145, Test Accuracy: 79.00%\nIdeally, the loss should steadily decrease to 0 while accuracy increases to 100%. However, we can see that although accuracy is steadily increasing, the loss remains almost stagnant. This may be due to the following reasons:\nDifference between loss function and accuracy metrics:\nLoss functions and accuracy metrics can respond differently to changes in predictions. For example, we are using nn.BCEWithLogitsLoss, which measures the difference between the predicted probabilities and the true labels, while accuracy simply counts the proportion of correct predictions. Accuracy is a more straightforward metric, reflecting whether predictions match the labels. In contrast, loss considers how confident the predictions are and penalizes incorrect predictions more if they are made with high confidence.\nPrediction probabilities and thresholding:\nTo classify the data, our model is using a threshold of 0.5 to convert prediction probabilities into binary predictions. Therefore, accuracy may appear high if the model’s predictions are often very close to the threshold. However, the loss function still evaluates based on the exact probability values, which might not improve if the model’s confidence is misplaced.\nLet’s plot the decision boundary of the model using both the train and test data to understand how well our model has learned.\n\n\n1.3.3 Visualizing the decision boundary\nA decision boundary is a line or a surface that separates different classes in a dataset. We’ll define plot_decision_boundary() function to plot the decision boundary for our dataset. It creates a grid of points covering the feature space, passes these points through the model to get predictions, and then plots these predictions along with the actual data points.\n\n\nCode\ndef plot_decision_boundary(model: torch.nn.Module, X: torch.Tensor, y: torch.Tensor):\n\n    \"\"\"Plot the decision boundary of a model's predictions on X against y.\"\"\"\n\n    # Ensure model and data are on CPU\n    device = torch.device(\"cpu\")\n    model.to(device)\n    X, y = X.to(device), y.to(device)\n\n    # Set up grid boundaries for plotting\n    x_min, x_max = X[:, 0].min().item() - 0.1, X[:, 0].max().item() + 0.1\n    y_min, y_max = X[:, 1].min().item() - 0.1, X[:, 1].max().item() + 0.1\n    xx, yy = np.meshgrid(\n        np.linspace(x_min, x_max, 101),\n        np.linspace(y_min, y_max, 101)\n    )\n\n    # Generate predictions for grid points\n    X_to_pred_on = torch.from_numpy(np.c_[xx.ravel(), yy.ravel()]).float().to(device)\n\n    model.eval()\n    with torch.no_grad():\n        y_logits = model(X_to_pred_on)\n\n    # Determine prediction labels based on problem type (binary vs. multi-class)\n    y_pred = (\n        torch.softmax(y_logits, dim=1).argmax(dim=1)\n        if y.unique().numel() &gt; 2\n        else torch.sigmoid(y_logits).round()\n    )\n\n    # Reshape predictions and plot the decision boundary\n    y_pred = y_pred.reshape(xx.shape).cpu().numpy()\n    plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)\n    plt.scatter(X[:, 0].cpu(), X[:, 1].cpu(), c=y.cpu(), s=40, cmap=plt.cm.RdYlBu)\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n\n\n\n\nCode\n# Plot decision boundaries for train set\n\nplt.figure(figsize=(6, 5))\nplt.title(\"Train data\")\nplot_decision_boundary(model, X_train, y_train)\nplt.show()\n\n\n\n\n\nCode\n# Plot decision boundaries for test set\n\nplt.figure(figsize=(6, 5))\nplt.title(\"Test data\")\nplot_decision_boundary(model, X_test, y_test)\nplt.show()\n\n\n\nFrom the above diagrams, we can see that our model is underfitting, but not to the extent suggested by the loss value. For a loss value of around 0.6, we would expect about half of the points to be misclassified, but that’s not the case here. Therefore, the accuracy metric is more appropriate for evaluating the model."
  },
  {
    "objectID": "projects/BnMclass/binaryNmulti.html#improve-the-model",
    "href": "projects/BnMclass/binaryNmulti.html#improve-the-model",
    "title": "Developing neural network models for classification problems using PyTorch",
    "section": "1.4 Improve the model",
    "text": "1.4 Improve the model\nSince our model is underfitting, we can improve the model in several ways, such as experimenting with different architectures, activation functions, or optimizers etc. As we have a simple problem to solve, let’s train it for another 1000 epochs and see what happens.\n\n\nCode\ntrain_and_evaluate(model, X_train, y_train, X_test, y_test, loss_fn, optimizer, epochs=1000, device=device)\n\n\nEpoch: 0 | Loss: 0.56818, Accuracy: 87.75% | Test Loss: 0.57378, Test Accuracy: 86.50%\nEpoch: 100 | Loss: 0.48153, Accuracy: 93.50% | Test Loss: 0.49935, Test Accuracy: 90.50%\nEpoch: 200 | Loss: 0.37056, Accuracy: 97.75% | Test Loss: 0.40595, Test Accuracy: 92.00%\nEpoch: 300 | Loss: 0.25458, Accuracy: 99.00% | Test Loss: 0.30333, Test Accuracy: 96.50%\nEpoch: 400 | Loss: 0.17180, Accuracy: 99.50% | Test Loss: 0.22108, Test Accuracy: 97.50%\nEpoch: 500 | Loss: 0.12188, Accuracy: 99.62% | Test Loss: 0.16512, Test Accuracy: 99.00%\nEpoch: 600 | Loss: 0.09123, Accuracy: 99.88% | Test Loss: 0.12741, Test Accuracy: 99.50%\nEpoch: 700 | Loss: 0.07100, Accuracy: 99.88% | Test Loss: 0.10319, Test Accuracy: 99.50%\nEpoch: 800 | Loss: 0.05773, Accuracy: 99.88% | Test Loss: 0.08672, Test Accuracy: 99.50%\nEpoch: 900 | Loss: 0.04853, Accuracy: 99.88% | Test Loss: 0.07474, Test Accuracy: 99.50%\nLooks like our model has converged and we got the results what we wanted i.e. loss close to zero and accuracy close to 100%. Now, let’s visualize the decision boundary to see what’s hapenning.\n\n\nCode\n# Plot decision boundaries for test set\n\nplt.figure(figsize=(6, 5))\nplt.title(\"Model Test\")\nplot_decision_boundary(model, X_test, y_test)\nplt.show()\n\n\n\nThe decision boundary plot also confirms that our model has improved.\nNow that we have done with our binary classification, let’s move on to multi-class classification problem."
  },
  {
    "objectID": "projects/BnMclass/binaryNmulti.html#prepare-and-explore-the-data-1",
    "href": "projects/BnMclass/binaryNmulti.html#prepare-and-explore-the-data-1",
    "title": "Developing neural network models for classification problems using PyTorch",
    "section": "2.1 Prepare and explore the data",
    "text": "2.1 Prepare and explore the data\nFirst, let’s import the required modules. We are re-importing most of the modules for the sake of completeness.\n\n\nCode\n# Import the required modules\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn\n\n\nNow, we will use the make_blobs() method from scikit-learn to generate isotropic Gaussian blobs.\n\n\nCode\n# Set the hyperparameters for data creation\n\nNUM_SAMPLES = 1000\nNUM_CLASSES = 4\nNUM_FEATURES = 2\nRANDOM_SEED = 42\n\n# Create multi-class data\n\nX_blob, y_blob = make_blobs(n_samples=NUM_SAMPLES,\n                            n_features=NUM_FEATURES, # X features\n                            centers=NUM_CLASSES, # y labels\n                            cluster_std=2, # standard deviation of the cluster\n                            random_state=RANDOM_SEED\n                            )\n\n# Count no. of samples per label\n\nunique_values, counts = np.unique(y_blob, return_counts=True)\nunique_counts_dict = {f'Label {val}': f'{count} samples' for val, count in zip(unique_values, counts)}\nprint(unique_counts_dict, end = '\\n\\n')\n\n# View ten samples\n\nprint(f\"Ten 'X' features:\\n{X_blob[-10:]}\")\nprint(f\"\\n Ten corresponding 'y' labels:\\n{y_blob[-10:]}\", end = '\\n\\n')\n\n\n{'Label 0': '250 samples', 'Label 1': '250 samples', 'Label 2': '250 samples', 'Label 3': '250 samples'}\n\nten X features:\n[[ 4.17800978  3.36558241]\n [-4.18864131  7.81550084]\n [ 5.25548237 -1.4471671 ]\n [-9.00985452 -7.490559  ]\n [ 6.93842549  0.56681683]\n [-2.75662004 -4.46337713]\n [-1.26095799 10.27097715]\n [ 2.74108106  7.23793381]\n [-8.0986516  -7.2540522 ]\n [-9.96266381  6.90507917]]\n\n ten corresponding y labels:\n[1 0 1 2 1 2 0 1 2 3]\nThe above make_blobs() function generates a balanced dataset with 1,000 samples, 2 features, 4 centers (clusters), and a specified spread within each cluster (cluster_std=2). The random_state parameter ensures that the data is the same every time it’s generated.\nNow, we will visualize our dataset.\n\n\nCode\n# Plot the dataset\n\nplt.figure(figsize=(10, 7))\nplt.scatter(X_blob[:, 0], X_blob[:, 1], c=y_blob, cmap=plt.cm.RdYlBu)\nplt.show()\n\n\n\nNow, let’s prepare our data for modeling with PyTorch.\n\n\nCode\n# Turn data into tensors\nX_blob = torch.tensor(X_blob, dtype=torch.float)\ny_blob = torch.tensor(y_blob, dtype=torch.long)\n\n\n\n\nCode\n# Split the data into train and test sets\n\nX_blob_train, X_blob_test, y_blob_train, y_blob_test = train_test_split(X_blob, y_blob, test_size=0.2, random_state=RANDOM_SEED)\n\n# Number of training and testing samples\n\nprint(f\"Number of training samples: {len(X_blob_train)}\")\nprint(f\"Number of testing samples: {len(X_blob_test)}\")\n\n\nNumber of training samples: 800\nNumber of testing samples: 200"
  },
  {
    "objectID": "projects/BnMclass/binaryNmulti.html#build-the-model-1",
    "href": "projects/BnMclass/binaryNmulti.html#build-the-model-1",
    "title": "Developing neural network models for classification problems using PyTorch",
    "section": "2.2 Build the model",
    "text": "2.2 Build the model\nNow that we have our data ready, we will build our model using PyTorch.\nSince our data appears to be linearly separable in the above plot, let’s use only linear layers in the model and see if it works.\n\n\nCode\nclass BlobModel(nn.Module):\n\n    def __init__(self, input_features, output_features, hidden_units=8):\n        super(BlobModel, self).__init__()\n        self.linear_layer_stack = nn.Sequential(\n            nn.Linear(input_features, hidden_units),\n            nn.Linear(hidden_units, hidden_units),\n            nn.Linear(hidden_units, output_features)\n        )\n\n    def forward(self, x):\n        return self.linear_layer_stack(x)"
  },
  {
    "objectID": "projects/BnMclass/binaryNmulti.html#train-and-evaluate-the-model-1",
    "href": "projects/BnMclass/binaryNmulti.html#train-and-evaluate-the-model-1",
    "title": "Developing neural network models for classification problems using PyTorch",
    "section": "2.3 Train and evaluate the model",
    "text": "2.3 Train and evaluate the model\nNow that we have our model ready, we will define the train_and_evaluate() function similarly to how we defined it for binary classification. This function will train and evaluate the model, running for a specified number of epochs, computing training and testing loss and accuracy, and printing the results every 100 epochs.\nWe have already discussed the steps involved in training and evaluating PyTorch models in the binary classification problem. For multi-class classification, we need to adjust the function to accommodate the specifics of this problem, such as the forward pass and the use of different loss functions and optimizers.\nIn the forward pass, the model outputs logits (raw predictions), which are then converted to predicted labels using the argmax() function.\nHere, we’ll use the nn.CrossEntropyLoss() method as our loss function. For the optimizer, we will use torch.optim.SGD() to optimize the model parameters with a learning rate of 0.1.\nAdditionally, we will use the previously defined accuracy_fn() function to evaluate accuracy.\n\n\nCode\ndef train_and_evaluate(model, X_blob_train, y_blob_train, X_blob_test, y_blob_test, loss_fn, optimizer, epochs=1000, device='cpu'):\n\n    # Ensure the model is on the correct device\n    model.to(device)\n\n    # Move data to the device\n    X_blob_train, y_blob_train = X_blob_train.to(device), y_blob_train.to(device)\n    X_blob_test, y_blob_test = X_blob_test.to(device), y_blob_test.to(device)\n\n    for epoch in range(epochs):\n\n        ## Trainig\n        model.train()\n\n        # Forward pass\n        y_logits = model(X_blob_train)\n        #y_pred = y_logits.argmax(dim=1)\n        y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)\n\n        # Calculate loss and accuracy\n        loss = loss_fn(y_logits, y_blob_train)\n        acc = accuracy_fn(y_blob_train, y_pred)\n\n        # Optimizer zero grad\n        optimizer.zero_grad()\n\n        # Loss backward\n        loss.backward()\n\n        # Optimizer step\n        optimizer.step()\n\n        ## Testing\n        model.eval()\n        with torch.no_grad():\n            test_logits = model(X_blob_test)\n            #test_pred = test_logits.argmax(dim=1)\n            test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n\n            # Calculate test loss and accuracy\n            test_loss = loss_fn(test_logits, y_blob_test)\n            test_acc = accuracy_fn(y_blob_test, test_pred)\n\n        # Print out what's happening\n        if epoch % 100 == 0:\n            print(f\"Epoch: {epoch} | Train Loss: {loss:.5f}, Train Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%\")\n\n\n\n2.3.1 Setup loss and optimizer\n\n\nCode\n# Set random seed for reproducibility\ntorch.manual_seed(42)\n\n# Setup device agnostic code\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Initialize model, loss function, and optimizer\nmodel = BlobModel(input_features=NUM_FEATURES, output_features=NUM_CLASSES, hidden_units=8)\n\n# Setup loss function\nloss_fn = nn.CrossEntropyLoss()\n\n# Setup optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n\n\nNow we will train and evaluate the model using the train_and_evaluate() function for 1000 epochs.\n\n\nCode\ntrain_and_evaluate(model, X_blob_train, y_blob_train, X_blob_test, y_blob_test, loss_fn, optimizer, epochs=1000, device=device)\n\n\nEpoch: 0 | Train Loss: 1.05193, Train Accuracy: 63.00% | Test Loss: 0.59764, Test Accuracy: 91.50%\nEpoch: 100 | Train Loss: 0.09545, Train Accuracy: 96.25% | Test Loss: 0.08077, Test Accuracy: 96.50%\nEpoch: 200 | Train Loss: 0.09102, Train Accuracy: 96.25% | Test Loss: 0.07636, Test Accuracy: 96.50%\nEpoch: 300 | Train Loss: 0.08858, Train Accuracy: 96.25% | Test Loss: 0.07355, Test Accuracy: 96.50%\nEpoch: 400 | Train Loss: 0.08655, Train Accuracy: 96.38% | Test Loss: 0.07098, Test Accuracy: 96.50%\nEpoch: 500 | Train Loss: 0.08469, Train Accuracy: 96.38% | Test Loss: 0.06858, Test Accuracy: 96.50%\nEpoch: 600 | Train Loss: 0.08296, Train Accuracy: 96.38% | Test Loss: 0.06633, Test Accuracy: 97.00%\nEpoch: 700 | Train Loss: 0.08133, Train Accuracy: 96.62% | Test Loss: 0.06422, Test Accuracy: 97.00%\nEpoch: 800 | Train Loss: 0.07980, Train Accuracy: 96.62% | Test Loss: 0.06224, Test Accuracy: 97.00%\nEpoch: 900 | Train Loss: 0.07844, Train Accuracy: 96.62% | Test Loss: 0.05917, Test Accuracy: 97.50%\n\n\n2.3.2 Visualizing the decision boundary\nHere we will use the previously defined plot_decision_boundary() function to plot the decision boundaries for our model.\n\n\nCode\n# Plot decision boundaries\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.title(\"Train data\")\nplot_decision_boundary(model, X_blob_train, y_blob_train)\n\nplt.subplot(1, 2, 2)\nplt.title(\"Test data\")\nplot_decision_boundary(model, X_blob_test, y_blob_test)\nplt.show()\n\n\n\nFrom the results above, we can see that our model has nearly 0 loss and 97% accuracy. This indicates that it is performing quite well, and there may be no need for further improvements."
  },
  {
    "objectID": "projects/MNIST/mnist.html",
    "href": "projects/MNIST/mnist.html",
    "title": "Nearest neighbor classifier for handwritten digit recognition",
    "section": "",
    "text": "In this project, we will build a classifier that takes an image of a handwritten digit and recognizes the digit present in the image. Convolutional Neural Networks (CNNs) are usually preferred for such tasks because they are specifically designed to handle the spatial and hierarchical nature of image data, making them highly effective.\nHowever, in this project, let’s explore a simple strategy to build a classifier based on nearest neighbors (NN). We will then examine methods to improve classification time by reducing the nearest neighbor search time."
  },
  {
    "objectID": "projects/MNIST/mnist.html#view-the-first-data-point-in-the-training-and-test-sets",
    "href": "projects/MNIST/mnist.html#view-the-first-data-point-in-the-training-and-test-sets",
    "title": "Nearest neighbor classifier for handwritten digit recognition",
    "section": "4.1 View the first data point in the training and test sets",
    "text": "4.1 View the first data point in the training and test sets\nNow that we have defined a function for visualizing the image, let’s see it in action by applying it to the first data points of the dataset.\n\n\nCode\n# View the first data point in the training set\n\nvis_image(0, \"train\")\n\n\n\n            Label 1\n\n\nCode\n# Now view the first data point in the test set\n\nvis_image(0, \"test\")\n\n\n\n            Label 5"
  },
  {
    "objectID": "projects/MNIST/mnist.html#test-the-euclidean-distance-function",
    "href": "projects/MNIST/mnist.html#test-the-euclidean-distance-function",
    "title": "Nearest neighbor classifier for handwritten digit recognition",
    "section": "5.1 Test the Euclidean distance function",
    "text": "5.1 Test the Euclidean distance function\nlet’s compute Euclidean distances of some random digits to see the squared_dist function in action before we use it in the NN classifier.\n\n\nCode\nprint('Examples:\\n')\n\n# Computing distances between random digits in our training set.\n\nprint(f\"Distance from digit {train_labels[3]} to digit {train_labels[5]} in our training set: {squared_dist(train_data[4],train_data[5])}\")\n\nprint(f\"Distance from digit {train_labels[3]} to digit {train_labels[1]} in our training set: {squared_dist(train_data[4],train_data[1])}\")\n\nprint(f\"Distance from digit {train_labels[3]} to digit {train_labels[7]} in our training set: {squared_dist(train_data[4],train_data[7])}\")\n\n\nExamples:\n\nDistance from digit 1 to digit 7 in our training set: 6720216.0\nDistance from digit 1 to digit 2 in our training set: 12104963.0\nDistance from digit 1 to digit 3 in our training set: 9038792.0"
  },
  {
    "objectID": "projects/MNIST/mnist.html#compute-the-classification-time-of-nn",
    "href": "projects/MNIST/mnist.html#compute-the-classification-time-of-nn",
    "title": "Nearest neighbor classifier for handwritten digit recognition",
    "section": "7.1 Compute the classification time of NN",
    "text": "7.1 Compute the classification time of NN\nSince the nearest neighbor classifier goes through the entire training set of 8000 images, searching for the nearest neighbor image for every single test image in the dataset of 2000 images, we should not expect testing to be very fast.\n\n\nCode\n# Compute the classification time of NN classifier\n\nprint(f\"Classification time of NN classifier: {round(t_after - t_before, 2)} sec\")\n\n\nClassification time of NN classifier: 227.05 sec"
  },
  {
    "objectID": "projects/MNIST/mnist.html#compute-the-error-rate-of-nn",
    "href": "projects/MNIST/mnist.html#compute-the-error-rate-of-nn",
    "title": "Nearest neighbor classifier for handwritten digit recognition",
    "section": "7.2 Compute the error rate of NN",
    "text": "7.2 Compute the error rate of NN\n\n\nCode\n# Compute the error rate \n\nerr_positions = np.not_equal(test_predictions, test_labels)\nerror = float(np.sum(err_positions))/len(test_labels)\n\nprint(f\"Error rate of nearest neighbor classifier: {round(error * 100, 2)}%\")\n\n\nError rate of nearest neighbor classifier: 5.45%\nThe error rate of the NN classifier is 5.45%. This means that out of the 2000 points, NN misclassifies around 109 of them, which is not too bad for such a simple method."
  },
  {
    "objectID": "projects/MNIST/mnist.html#k-d-tree-algorithm",
    "href": "projects/MNIST/mnist.html#k-d-tree-algorithm",
    "title": "Nearest neighbor classifier for handwritten digit recognition",
    "section": "8.1 k-d tree algorithm",
    "text": "8.1 k-d tree algorithm\nThe key advantage of the k-d tree is its ability to significantly reduce the number of distance calculations needed during a nearest neighbor search by efficiently pruning regions of the search space. This algorithm is based on the triangle inequality, utilizing the fact that if point ‘a’ is significantly far from point ‘b,’ and point ‘b’ is in close proximity to point ‘c,’ we can infer that points ‘a’ and ‘c’ are also distant from each other without explicitly calculating their distance.\nThis way, the computational cost of a nearest neighbors search can be reduced to \\(O(dNlog(N))\\) or better.\n\n\nCode\n# Build nearest neighbor structure on training data\n\nt_before = time.time()\nkd_tree = KDTree(train_data)\nt_after = time.time()\n\n## Compute training time\nt_training = t_after - t_before\nprint(f\"Time to build data structure: {round(t_training, 2)} sec\")\n\n## Get nearest neighbor predictions on testing data\nt_before = time.time()\ntest_neighbors = np.squeeze(kd_tree.query(test_data, k=1, return_distance=False))\nkd_tree_predictions = train_labels[test_neighbors]\nt_after = time.time()\n\n## Compute testing time\nt_testing = t_after - t_before\nprint(f\"Time to classify test set: {round(t_testing, 2)} sec\", end = '\\n\\n')\n\n## total classification time\n\nprint(f\"Overall classification time of k-d tree algorithm: {round(t_training+t_testing, 2)} sec\")\n\n\n## Verify that the predictions are the same\nprint(\"Does k-d tree produce same predictions as NN classifier? \", np.array_equal(test_predictions, kd_tree_predictions))\n\n\nTime to build data structure: 0.99 sec\nTime to classify test set: 20.35 sec\n\nOverall classification time of k-d tree algorithm: 21.34 sec\nDoes k-d tree produce same predictions as NN classifier?  True\nWe can see that the baseline nearest neighbor model and the k-d tree algorithm produce the same predictions, but the key difference is that the k-d tree is significantly faster than the former. It just took 21.34 sec to classify the whole test set."
  },
  {
    "objectID": "projects/ParseTrees/ParsetreesNnounphrases.html",
    "href": "projects/ParseTrees/ParsetreesNnounphrases.html",
    "title": "Generating parse trees and extracting noun phrases",
    "section": "",
    "text": "In Natural Language Processing (NLP), parsing refers to the process of analyzing a sentence to identify its grammatical structure. This is useful for a number of reasons, such as understanding sentence structure, resolving ambiguities in sentences, and better extraction of information from sentences.\nIn this project, we will work with the following English sentences and apply the context-free grammar (CFG) formalism to generate a parse tree or syntactic tree that represents the syntactic structure of the given sentences. Then, we will extract noun phrases from those sentences.\nSentences to analyze:"
  },
  {
    "objectID": "projects/ParseTrees/ParsetreesNnounphrases.html#cfg-rules",
    "href": "projects/ParseTrees/ParsetreesNnounphrases.html#cfg-rules",
    "title": "Generating parse trees and extracting noun phrases",
    "section": "1.1 CFG rules",
    "text": "1.1 CFG rules\nA rewriting rule in a CFG has the following form:\n𝐴 → 𝛼\nWhere: * 𝐴 is a non-terminal symbol and * 𝛼 is a string consisting of terminal and/or non-terminal symbols.\nNow, let’s define a concrete set of rules for generating terminal symbols and non-terminal symbols.\n\n1.1.1 Terminal symbols\nTerminal symbols represent the words in the sentence. The rules for generating these terminal symbols are defined in the global variable TERMINALS, which includes all the words of the given sentences to analyze. Notice that Adj is a nonterminal symbol that generates adjectives, Adv generates adverbs, Conj generates conjunctions, Det generates determiners, N generates nouns (spread across multiple lines for readability), P generates prepositions, and V generates verbs. The vertical bar | denotes all the terminal symbol alternatives for that particular non-terminal symbol.\n\n\nCode\nTERMINALS = \"\"\"\nAdj -&gt; \"country\" | \"dreadful\" | \"enigmatical\" | \"little\" | \"moist\" | \"red\"\nAdv -&gt; \"down\" | \"here\" | \"never\"\nConj -&gt; \"and\" | \"until\"\nDet -&gt; \"a\" | \"an\" | \"his\" | \"my\" | \"the\"\nN -&gt; \"armchair\" | \"companion\" | \"day\" | \"door\" | \"hand\" | \"he\" | \"himself\"\nN -&gt; \"holmes\" | \"home\" | \"i\" | \"mess\" | \"paint\" | \"palm\" | \"pipe\" | \"she\"\nN -&gt; \"smile\" | \"thursday\" | \"walk\" | \"we\" | \"word\" \nP -&gt; \"at\" | \"before\" | \"in\" | \"of\" | \"on\" | \"to\" \nV -&gt; \"arrived\" | \"came\" | \"chuckled\" | \"had\" | \"lit\" | \"said\" | \"sat\"\nV -&gt; \"smiled\" | \"tell\" | \"were\" \n\"\"\"\n\n\n\n\n1.1.2 Non-terminal symbols\nNon-terminal symbols are syntactic variables that represent sets of strings. Common non-terminals include parts of speech (e.g., noun, verb) and phrases (e.g., noun phrase, verb phrase). These symbols are defined in the global variable called NONTERMINALS and it contains all the rules for generating non-terminal symbols.\nThe description of symbols is as follows: S represents a complete sentence, NP represents a noun phrase, VP represents a verb phrase, PP represents a prepositional phrase, Det represents a determiner, and AP represents an adjective phrase. Each alternative separated by the vertical bar | represents a different way that a non-terminal can be replaced by a sequence of terminals and/or non-terminals. We can notice that all these rules are self-explanatory. For example, a rule like AP → Adj | Adj AP indicates that an adjective phrase can be formed either by an adjective or by an adjective followed by an adjective phrase.\n\n\nCode\nNONTERMINALS = \"\"\"\nS -&gt; NP VP | VP NP | S Conj S\n\nNP -&gt; N | Det N | NP PP | Det AP N\nVP -&gt; V | V NP | V PP | Adv VP | VP Adv\nAP -&gt; Adj | Adj AP\nPP -&gt; P NP\n\"\"\""
  },
  {
    "objectID": "projects/SQLMuseum/mfa.html",
    "href": "projects/SQLMuseum/mfa.html",
    "title": "Soft deletions, views, and triggers in the context of a museum’s database",
    "section": "",
    "text": "In this project, we will explore the concepts of soft deletions, views, and triggers in the context of the Museum of Fine Arts (MFA). The MFA is a century-old museum housing numerous historical and contemporary artifacts and artworks. It manages its extensive collection through the MFA database, which tracks thousands of items. However, for the purpose of this project, we will work with a subset of the database containing only ten items in the collections table.\n\n\n\n\n\nER diagram of the MFA database\n\n\nThe Schema of the MFA database is shown above. The collections table contains the following columns:\n\nid, which is the ID of the table that serves as the primary key\ntitle, which is the name of the art piece\naccession_number, which is a unique ID used by the museum internally\nacquired, which indicates when the art was acquired\n\nLet us now establish the SQLite connection to the database using DBI package.\n\n\nCode\nlibrary(DBI)\ncon &lt;- dbConnect(RSQLite::SQLite(), \"mfa.db\") # establish SQLite connection to the database\n\n\nThe data of the collections table is as follows:\n\n\nCode\nSELECT * FROM \"collections\";\n\n\n\nDisplaying records 1 - 10\n\n\nid\ntitle\naccession_number\nacquired\n\n\n\n\n1\nProfusion of flowers\n56.257\n1956-04-12\n\n\n2\nFarmers working at dawn\n11.6152\n1911-08-03\n\n\n3\nSpring outing\n14.76\n1914-01-08\n\n\n4\nImaginative landscape\n56.496\nNA\n\n\n5\nPeonies and butterfly\n06.1899\n1906-01-01\n\n\n6\nTile Lunette\n06.2437\n1906-11-08\n\n\n7\nStatuette of a shrew\n01.105\n1901-02-11\n\n\n8\nCountry road with culvert\n76.431\nNA\n\n\n9\nFamily of acrobats\n1974.352\n1933-03-30\n\n\n10\nBacchic scene with minotaur\n1974.379\n1933-05-18"
  },
  {
    "objectID": "projects/SQLMuseum/mfa.html#schema",
    "href": "projects/SQLMuseum/mfa.html#schema",
    "title": "Soft deletions, views, and triggers in the context of a museum’s database",
    "section": "",
    "text": "ER diagram of the MFA database\n\n\nThe Schema of the MFA database is shown above. The collections table contains the following columns:\n\nid, which is the ID of the table that serves as the primary key\ntitle, which is the name of the art piece\naccession_number, which is a unique ID used by the museum internally\nacquired, which indicates when the art was acquired\n\nLet us now establish the SQLite connection to the database using DBI package.\n\n\nCode\nlibrary(DBI)\ncon &lt;- dbConnect(RSQLite::SQLite(), \"mfa.db\") # establish SQLite connection to the database\n\n\nThe data of the collections table is as follows:\n\n\nCode\nSELECT * FROM \"collections\";\n\n\n\nDisplaying records 1 - 10\n\n\nid\ntitle\naccession_number\nacquired\n\n\n\n\n1\nProfusion of flowers\n56.257\n1956-04-12\n\n\n2\nFarmers working at dawn\n11.6152\n1911-08-03\n\n\n3\nSpring outing\n14.76\n1914-01-08\n\n\n4\nImaginative landscape\n56.496\nNA\n\n\n5\nPeonies and butterfly\n06.1899\n1906-01-01\n\n\n6\nTile Lunette\n06.2437\n1906-11-08\n\n\n7\nStatuette of a shrew\n01.105\n1901-02-11\n\n\n8\nCountry road with culvert\n76.431\nNA\n\n\n9\nFamily of acrobats\n1974.352\n1933-03-30\n\n\n10\nBacchic scene with minotaur\n1974.379\n1933-05-18"
  },
  {
    "objectID": "projects/SQLMuseum/mfa.html#problem-1-soft-deleting-the-artworks",
    "href": "projects/SQLMuseum/mfa.html#problem-1-soft-deleting-the-artworks",
    "title": "Soft deletions, views, and triggers in the context of a museum’s database",
    "section": "2.1 Problem 1: Soft deleting the artworks",
    "text": "2.1 Problem 1: Soft deleting the artworks\n\n\n\n\n\n\nImplement a soft deletion of items in the collections table, where a log of sold artworks is kept in the column named “deleted” instead of completely removing them from the table, so that the records of artworks in the collection are not lost. The “deleted” column in the collections table must have a value of 0 for the available items for sale and a value of 1 for the items that have been sold. Imagine the artworks “Farmers Working at Dawn” and “Tile Lunette” were sold, and implement this idea of soft deletion on them."
  },
  {
    "objectID": "projects/SQLMuseum/mfa.html#problem-2-view-that-shows-only-available-artworks",
    "href": "projects/SQLMuseum/mfa.html#problem-2-view-that-shows-only-available-artworks",
    "title": "Soft deletions, views, and triggers in the context of a museum’s database",
    "section": "2.2 Problem 2: View that shows only available artworks",
    "text": "2.2 Problem 2: View that shows only available artworks\n\n\n\n\n\n\nCreate a view named current_collections using all the columns of the collections table except the “deleted” column, so that the view can be used to display only the information about the artworks that are available for sale."
  },
  {
    "objectID": "projects/SQLMuseum/mfa.html#problem-3-trigger-that-soft-deletes-the-artworks",
    "href": "projects/SQLMuseum/mfa.html#problem-3-trigger-that-soft-deletes-the-artworks",
    "title": "Soft deletions, views, and triggers in the context of a museum’s database",
    "section": "2.3 Problem 3: Trigger that soft deletes the artworks",
    "text": "2.3 Problem 3: Trigger that soft deletes the artworks\n\n\n\n\n\n\nSince data in the view cannot be modified directly, create a trigger on the current_collections view that soft deletes the data from the underlying collections table, as per the idea of soft deletion discussed above. The trigger must be activated when any data is attempted to be deleted from the view. Demonstrate this trigger by selling all the artworks that have no acquired date."
  },
  {
    "objectID": "projects/SQLMuseum/mfa.html#problem-4-trigger-that-reverses-the-soft-deletion-of-artworks",
    "href": "projects/SQLMuseum/mfa.html#problem-4-trigger-that-reverses-the-soft-deletion-of-artworks",
    "title": "Soft deletions, views, and triggers in the context of a museum’s database",
    "section": "2.4 Problem 4: Trigger that reverses the soft deletion of artworks",
    "text": "2.4 Problem 4: Trigger that reverses the soft deletion of artworks\n\n\n\n\n\n\nImagine the items sold in the task 3 are rebought. Now, create a trigger on the current_collections view that reverses the soft deletion, i.e., setting the corresponding row’s deleted value to 0 in the underlying collections table to indicate that the items are again available. The trigger must be executed when any soft-deleted data is attempted to be inserted into the current_collections view."
  },
  {
    "objectID": "projects/SQLMuseum/mfa.html#problem-5-trigger-that-inserts-new-artworks",
    "href": "projects/SQLMuseum/mfa.html#problem-5-trigger-that-inserts-new-artworks",
    "title": "Soft deletions, views, and triggers in the context of a museum’s database",
    "section": "2.5 Problem 5: Trigger that inserts new artworks",
    "text": "2.5 Problem 5: Trigger that inserts new artworks\n\n\n\n\n\n\nCreate a trigger on the current_collections view that inserts new data into the underlying collections table when any new data is attempted to be inserted into the view. Demonstrate this trigger by buying new artworks ‘Adoration of the Magi’ (accession_number: 1971.71, acquired: 2022-01-11) and ‘Agony in the Garden’ (accession_number: 68.206, acquired: 2022-05-01)."
  }
]